{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic: Conditional Random Fields\n",
    "\n",
    "London Data Science Journal Club, Oct 2019"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "\n",
    "\n",
    "- A probablistic approach for modelling sequential data and making structured prediction\n",
    "- Viewed as a special case of Markov Random Fields, and general PGMs.\n",
    "- Wide applications in NLP and Computer Vision, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Fields\n",
    "\n",
    "A random field is a function whose codomain is $\\{F_{v}: v \\in V \\}$ where\n",
    "- $v$ is index of elements in some $n$-dimensioned space $V$;\n",
    "- $F_{v}$ is a $d$-dimensioned random variable at $v$.\n",
    "<div style=\"text-align: right\"> wikipedia, 2019 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov Random Fields\n",
    "\n",
    "Given an undirected graph $G = (V, E)$, a random field whose collection is indexed by $V$ is known as MRF with respect to G if local markov property is satistfied such that:\n",
    "\n",
    "$$F_v \\perp\\!\\!\\!\\perp F_{V\\setminus{\\{\\partial_v}, v\\}} \\mid F_{\\partial_v}$$\n",
    "\n",
    "where $\\partial_v$ is the open neighbourhood of $F_v$, also known as <i>Markov blanket</i> of $F_v$ in an undirected graph.\n",
    "<figure>\n",
    "<center><img src=\"https://ermongroup.github.io/cs228-notes/assets/img/markovblanket.png\" width=\"300\">\n",
    "    <figcaption><font size=\"-1\">Markov blanket of X in an undirected graph.</font></figcaption></center>\n",
    "</figure>\n",
    "<div style=\"text-align: right\"> wikipedia, 2019 </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conditional Random Fields\n",
    "\n",
    "Consider the same graph $G$, $(X, Y)$ is a CRF if random variables $(Y_v)_{v \\in V}$ <i>globally</i> conditioned on $X$ satisfy markov property w.r.t. $G$:\n",
    "\n",
    "$$p(Y_v \\mid X, Y_{V\\setminus{v}}) =  p(Y_v \\mid X, Y_{\\partial_v})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear-chain CRF\n",
    "\n",
    "from a $n$-dimensional random field to 1-dimensional stochastic process to trade generalizability for tractability.\n",
    "\n",
    "<figure>\n",
    "<center><img src=\"http://www.davidsbatista.net/assets/images/2017-11-13-Conditional_Random_Fields.png\" width=\"250\">\n",
    "    <figcaption><font size=\"-1\">Linear-chain CRF globally conditioned on <b>X</b>. Wallach H. 2004</font></figcaption></center></figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "<center><img src=\"http://www.davidsbatista.net/assets/images/2017-11-13-HMM-MEMM-CRF.png\" width=\"600\">\n",
    "    <figcaption><font size=\"-1\">HMM, MEMM, and CRF respectively. Open circles indicate not generated by model. Lafferty et al. 2001</font></figcaption></center></figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "<center><img src=\"http://www.davidsbatista.net/assets/images/2017-11-13-CRF_Equation.png\" width=\"300\">\n",
    "    <figcaption><font size=\"-1\">Markov blanket in undirected graph. Bishop C. 2006</font></figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy\n",
    "Q. why gibbs distribution as potential function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
